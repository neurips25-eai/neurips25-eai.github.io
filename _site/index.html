<!DOCTYPE html>
<html lang=" en-US">

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    
    <meta charset="UTF-8">

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>From Thought to Action: The Embodied Agent Interface Challenge for Next-Generation Intelligent Agents | Official Website for NeurIPS 2025 Embodied Agent Interface Competition</title>
<meta name="generator" content="Jekyll v3.9.3">
<meta property="og:title" content="From Thought to Action: The Embodied Agent Interface Challenge for Next-Generation Intelligent Agents">
<meta property="og:locale" content="en_US">
<meta name="description" content="Official Website for NeurIPS 2025 Embodied Agent Interface Competition">
<meta property="og:description" content="Official Website for NeurIPS 2025 Embodied Agent Interface Competition">
<link rel="canonical" href="http://localhost:4000/">
<meta property="og:url" content="http://localhost:4000/">
<meta property="og:site_name" content="From Thought to Action: The Embodied Agent Interface Challenge for Next-Generation Intelligent Agents">
<meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="From Thought to Action: The Embodied Agent Interface Challenge for Next-Generation Intelligent Agents">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"Official Website for NeurIPS 2025 Embodied Agent Interface Competition","headline":"From Thought to Action: The Embodied Agent Interface Challenge for Next-Generation Intelligent Agents","name":"From Thought to Action: The Embodied Agent Interface Challenge for Next-Generation Intelligent Agents","url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&amp;display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  
    <!-- KaTeX -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>

    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <style type="text/css">
        /* Style the tab */
        .tab {
            overflow: hidden;
            border: 1px solid #ccc;
            background-color: #fdfdff;
        }

        /* Style the buttons that are used to open the tab content */
        .tab button {
            background-color: inherit;
            float: left;
            border: none;
            outline: none;
            cursor: pointer;
            padding: 14px 16px;
            transition: 0.3s;
        }

        /* Change background color of buttons on hover */
        .tab button:hover {
            background-color: #ddd;
        }

        /* Create an active/current tablink class */
        .tab button.active {
            background-color: #ccc;
        }

        /* Style the tab content */
        .tabcontent {
            display: none;
            padding: 6px 12px;
            border: 1px solid #ccc;
            border-top: none;
        }
    </style>


</head>

<body>
    <header class="page-header" role="banner">
        <h1 class="project-name">From Thought to Action: The Embodied Agent Interface Challenge for Next-Generation Intelligent Agents</h1>
        <h1 class="project-tagline">Official Website for NeurIPS 2025 Embodied Agent Interface Competition</h1>
        
        <a href="index" class="btn">Overview</a>
        
        <a href="schedule" class="btn">Schedule</a>
        
        <a href="rules" class="btn">Rules</a>
        
        <a href="incentives" class="btn">Incentives</a>
        
        <a href="starter_kit" class="btn">Starter Kit</a>
        
        <a href="organizers" class="btn">Organizers</a>
        

    </header>

    <main id="content" class="main-content" role="main">
        <h1 id="embodied-agent-interface-challenge--neurips-2025">Embodied Agent Interface Challenge @ NeurIPS 2025</h1>

<p>Welcome to the <strong>Embodied Agent Interface (EAI) Challenge</strong>, a NeurIPS 2025 competition that introduces a unified benchmarking framework for evaluating <strong>Large Language Models (LLMs)</strong> in <strong>embodied decision-making tasks</strong>. This competition aims to foster reproducible research and rigorous analysis in embodied AI, bridging the gap between language modeling and robotic planning.</p>

<h2 id="-motivation">üß† Motivation</h2>

<p>Despite increasing interest in using LLMs for robotics and agent reasoning, current evaluations are fragmented and often limited to final task success rates. These approaches fail to reveal specific reasoning failures, limiting scientific understanding and practical progress.</p>

<p>The <strong>Embodied Agent Interface</strong> addresses this gap through a <strong>modular evaluation framework</strong> that standardizes task interfaces and metrics across four core decision-making abilities:</p>

<ul>
  <li><strong>Goal Interpretation</strong></li>
  <li><strong>Subgoal Decomposition</strong></li>
  <li><strong>Action Sequencing</strong></li>
  <li><strong>Transition Modeling</strong></li>
</ul>

<h2 id="-whats-new">üî¨ What‚Äôs New?</h2>

<ul>
  <li>
<strong>Standardized Interface</strong> for embodied reasoning across symbolic and simulation-based tasks.</li>
  <li>
<strong>Linear Temporal Logic (LTL)</strong> is used to formally specify both state-based and temporally extended goals.</li>
  <li>
<strong>Fine-grained error metrics</strong>, including hallucination rates, precondition violations, and planning logic mismatches.</li>
  <li>Modular benchmarking on two powerful simulation platforms: <strong>BEHAVIOR</strong> and <strong>VirtualHome</strong>.</li>
</ul>

<h2 id="-benchmark-overview">üß™ Benchmark Overview</h2>

<p>The benchmark dataset consists of:</p>

<ul>
  <li>‚úÖ 338 tasks in <strong>VirtualHome</strong> across 26 categories</li>
  <li>‚úÖ 100 tasks in <strong>BEHAVIOR</strong> with complex physical goals</li>
  <li>‚úÖ LTL-annotated goals, symbolic trajectories, and PDDL-style transition models</li>
  <li>‚úÖ Support for interpretable and reproducible evaluation</li>
</ul>

<p>All data, annotations, and code will be released through our <a href="https://github.com/neurips25-eai">GitHub repository</a> and Hugging Face Datasets.</p>

<h2 id="-tasks--abilities">üß© Tasks &amp; Abilities</h2>

<p>Participants may compete in one or more of the following modules:</p>

<ol>
  <li>
<strong>Goal Interpretation</strong>: Translate natural language into formal symbolic goals.</li>
  <li>
<strong>Subgoal Decomposition</strong>: Break down goals into executable substeps.</li>
  <li>
<strong>Action Sequencing</strong>: Generate feasible action trajectories to accomplish goals.</li>
  <li>
<strong>Transition Modeling</strong>: Infer preconditions and effects of symbolic actions.</li>
</ol>

<p>Each module can be tackled independently, with leaderboards and evaluation scripts provided per module.</p>

<h2 id="-evaluation-metrics">üìä Evaluation Metrics</h2>

<p>We evaluate models on:</p>

<ul>
  <li>
<strong>Symbolic Accuracy</strong> (F1 scores for logic form generation)</li>
  <li>
<strong>Trajectory Feasibility</strong> (simulator execution success)</li>
  <li>
<strong>Goal Satisfaction</strong> (whether the plan achieves the intended goal)</li>
  <li>
<strong>Planner Compatibility</strong> (whether inferred models support planning)</li>
</ul>

<p>An aggregated <strong>Average Performance</strong> metric summarizes overall model capability across modules.</p>

<h2 id="-baselines--starter-kit">üöÄ Baselines &amp; Starter Kit</h2>

<p>We provide baseline implementations using open and proprietary LLMs:</p>

<ul>
  <li>GPT-4o</li>
  <li>Claude 3.5 Sonnet</li>
  <li>Llama 3-70B</li>
  <li>Gemini 1.5 Pro</li>
  <li>Mistral Large</li>
</ul>

<p>A <strong>comprehensive starter kit</strong> will include:</p>

<ul>
  <li>Data loaders for BEHAVIOR and VirtualHome</li>
  <li>Evaluation scripts with diagnostic metrics</li>
  <li>Reference code for each module</li>
  <li>Docker support and tutorial notebooks</li>
</ul>

<h2 id="-timeline">üìÖ Timeline</h2>

<table>
  <thead>
    <tr>
      <th>Phase</th>
      <th>Dates (2025)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Beta Testing</td>
      <td>July</td>
    </tr>
    <tr>
      <td>Competition Launch</td>
      <td>August</td>
    </tr>
    <tr>
      <td>Development Phase</td>
      <td>August ‚Äì Mid-October</td>
    </tr>
    <tr>
      <td>Final Evaluation</td>
      <td>Mid‚ÄìLate October</td>
    </tr>
    <tr>
      <td>NeurIPS Workshop</td>
      <td>November</td>
    </tr>
  </tbody>
</table>

<h2 id="-awards--recognition">üèÜ Awards &amp; Recognition</h2>

<ul>
  <li>Top 3 teams will present at the <strong>NeurIPS 2025 Workshop</strong>
</li>
  <li>Co-authorship on the <strong>official competition report</strong>
</li>
  <li>
<strong>Cash prizes</strong> (pending sponsorship)</li>
  <li>
<strong>Travel support</strong> for underrepresented participants</li>
</ul>

<h2 id="-how-to-participate">üìå How to Participate</h2>

<ul>
  <li>Register via <a href="https://eval.ai/">EvalAI</a>
</li>
  <li>Follow instructions in the <a href="https://github.com/neurips25-eai">starting kit</a>
</li>
  <li>Submit predictions or Docker images</li>
  <li>Track your performance on the public leaderboard</li>
</ul>

<h2 id="-stay-connected">üì£ Stay Connected</h2>

<ul>
  <li>üí¨ Join the community on Discord/Slack (invite link coming soon)</li>
  <li>üêõ File issues on our <a href="https://github.com/neurips25-eai">GitHub</a>
</li>
  <li>üìß Contact us at: <code class="language-plaintext highlighter-rouge">TianweiBao@u.northwestern.edu</code>
</li>
</ul>

<hr>

<p><strong>Let‚Äôs build the future of intelligent embodied agents ‚Äî together.</strong></p>


        <footer class="site-footer">
            <hr>
            <!-- 
            <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub
                    Pages</a>.</span> -->
        </footer>
    </main>

</body>

</html>
